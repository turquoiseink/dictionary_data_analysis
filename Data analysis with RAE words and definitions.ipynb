{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<img src=\"https://dle.rae.es/app/doc/es/img/dle.jpg\"\n",
    "    style=\"width:100px; float: right; margin: 0 40px 40px 40px;\"></img>\n",
    "\n",
    "<hr style=\"margin-bottom: 40px;\">\n",
    "\n",
    "# Data analysis with RAE words and definitions\n",
    "<hr style=\"margin-bottom: 1px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Theoretical introduction\n",
    "####      1.1 Libraries and modules used\n",
    "\n",
    "* Pandas: Data analysis\n",
    "\n",
    "* Numpy: Efficient calculus\n",
    "\n",
    "* Matplotlib: Data representation\n",
    "\n",
    "* Requests and Urllib: Obtain the HTML from web-pages\n",
    "\n",
    "* BeautifulSoup: Parse the obtained HTML from web-pages\n",
    "\n",
    "* LXML (module): Process the HTML code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 How does the program work?\n",
    "#### 2.1. The words list\n",
    "\n",
    "#### 2.2. Obtaining the data from each word\n",
    "The words are obtained from: https://www.listapalabras.com/\n",
    "\n",
    "We use a function called word_data(word) that extracts all the data from the dictionary entry of the word.\n",
    "\n",
    "    Definitions URL: https://dle.rae.es/{'word'}\n",
    "#### 2.3. Type of data extracted from each word\n",
    "* Different entries\n",
    "* Ethimological origin\n",
    "* Gramatical word type\n",
    "* Definitions\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 The program:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All the libraries\n",
    "\n",
    "from bs4 import Tag, NavigableString, BeautifulSoup\n",
    "import requests\n",
    "from urllib.request import Request, urlopen\n",
    "import urllib.parse \n",
    "import urllib.error\n",
    "import csv\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The files where data is going to be stored:\n",
    "\n",
    "#Every line in dictionary contains:\n",
    "#  |word|article_i|def_j|[Abbr1, Abbr2, ...]|Definition|\n",
    "f=open('dictionary_RAE_all.csv', 'w', encoding='UTF8')\n",
    "dic_file = csv.writer(f)\n",
    "dic_file.writerow(['Word', 'Article_number', 'Def_number', 'Abbreviation', 'Definition'])\n",
    "\n",
    "#Every line in etymology contains:\n",
    "#  |word|article_i|Ethimological origin|\n",
    "g=open('etymology_RAE_all.csv', 'w', encoding='UTF8')\n",
    "etm_file = csv.writer(g)\n",
    "etm_file.writerow(['Word', 'Article Num.', 'Ethimological origin'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This downloads the HTML file from an URL\n",
    "\n",
    "UA=\"Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:47.0) Gecko/20100101 Firefox/47.0\"\n",
    "\n",
    "url=\"https://dle.rae.es/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This loads the words that want to be analised in a list of string\n",
    "with open('words_all_list.csv', encoding=\"utf8\") as csv_file:\n",
    "    reader = csv.reader(csv_file)\n",
    "    words = list(reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computed: 51.469%\r"
     ]
    }
   ],
   "source": [
    "#This part extracts all the desired data from the HTML downloaded\n",
    "begin_time = time.time()\n",
    "\n",
    "n_word=0\n",
    "for word in words: #loop for every word to be searched\n",
    "    \n",
    "    for try_ in range(1,6): #The code will try this 5 times if it does not work\n",
    "        try: \n",
    "            req = Request(url+urllib.parse.quote(word[0]), headers={'User-Agent': UA})\n",
    "            soup = BeautifulSoup(urlopen(req), 'html.parser')\n",
    "            break\n",
    "        except: #the exception is designed for connection errors (eg. HTTP 520), and just waits and tries again\n",
    "            time.sleep(5)\n",
    "            req = Request(url+urllib.parse.quote(word[0]), headers={'User-Agent': UA})\n",
    "            soup = BeautifulSoup(urlopen(req), 'html.parser')\n",
    "        \n",
    "    i=0\n",
    "    for articles in soup.find_all('header',class_='f'): # loop for the different articles that has every word\n",
    "        i=i+1\n",
    "        j=0\n",
    "        article=articles.parent\n",
    "\n",
    "        etm_text='' #Etimology\n",
    "        \n",
    "        if article.find_all('p',class_='n2')!=[]: #Check if this definition has a known etymology\n",
    "            for child in article.find_all('p',class_='n2')[0]: #loop for every element in etymology\n",
    "                if child.name=='abbr': #prints the abbreviation\n",
    "                    etm_text = etm_text + str('{} '.format(child['title']))\n",
    "                elif isinstance(child, NavigableString) or child.name!='sup' or child.name!='sub': # prints all normal words\n",
    "                    etm_text = etm_text + str(child.string)\n",
    "            #The ETYMOLOGY entry\n",
    "            etm_file.writerow([word,'Article{}'.format(i),etm_text])\n",
    "\n",
    "        elif article.find_all('p',class_='n3')!=[]: #Check if this definition has a known etymology (other type)\n",
    "            for child in article.find_all('p',class_='n3')[0]: #loop for every element in etymology\n",
    "                if child.name=='abbr': #prints the abbreviation\n",
    "                    etm_text = etm_text + str('{} '.format(child['title']))\n",
    "                elif isinstance(child, NavigableString) or child.name!='sup' or child.name!='sub': # prints all normal words\n",
    "                    etm_text = etm_text + str(child.string)\n",
    "                #The ETYMOLOGY entry\n",
    "                etm_file.writerow([word,'Article{}'.format(i),etm_text])\n",
    "\n",
    "            \n",
    "        for definition in article.find_all('p',class_=['j', 'j1']):  #loop between every definition\n",
    "            j=j+1\n",
    "            def_text='' #Definition\n",
    "            def_abbr=[] #Abbreviations\n",
    "            for child in definition: #loop for every element in definition\n",
    "\n",
    "                if not (child.name=='span' and child['class']=='h'): #removes examples\n",
    "                    \n",
    "                    if child.name=='abbr': #prints the abbreviation\n",
    "                        if child['title']=='por ejemplo': #removes abbr examples, this should be manually revised !!\n",
    "                            def_abbr.append(child['title'])\n",
    "                            break\n",
    "                        else:\n",
    "                            def_abbr.append(child['title'])\n",
    "                            def_text = def_text + str(child['title'])\n",
    "                            \n",
    "                    elif child.name=='sub': #subindices\n",
    "                        def_text = def_text + str('_{}'.format(child.string))\n",
    "                        \n",
    "                    elif child.name=='sup': #superindices\n",
    "                        def_text = def_text + str('^{}'.format(child.string))\n",
    "\n",
    "                    elif isinstance(child, NavigableString) or child.has_attr(\"data-id\") or \\\n",
    "                    child.name=='a' or child.name=='i' or child['class'][0]=='u':\n",
    "                        if child.name=='a': #for synonims\n",
    "                            def_text = def_text + ''.join([char for char in child.get_text(' ') if not char.isdigit()])\n",
    "                        elif isinstance(child, Tag) and len(child.find_all()) != 0:\n",
    "                            def_text = def_text + ''.join([str(char.string) for char in child])\n",
    "                        else: # prints all normal words\n",
    "                            def_text = def_text + str(child.string)\n",
    "                            \n",
    "            #The DICTIONARY entry\n",
    "            dic_file.writerow([word[0],i,j, '; '.join(def_abbr), def_text.strip()])\n",
    "    n_word+=1\n",
    "    print('Computed: {}%'.format(round(n_word/len(words)*100, 3)), end = \"\\r\")\n",
    "\n",
    "f.close()\n",
    "g.close()\n",
    "\n",
    "end_time = time.time() - begin_time\n",
    "\n",
    "print(\"Total execution time: {} minutes.\".format(end_time/60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All the libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from string import punctuation\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Transform the string data to list type\n",
    "\n",
    "df = pd.read_csv('dictionary_RAE_c.csv')\n",
    "for i in range(0,len(df)):\n",
    "    df['Abbreviation'][i]=df['Abbreviation'][i].split(\"; \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reformat the abbreviations list into a dictionary\n",
    "\n",
    "with open('abbreviation_list_v1.csv', newline='', encoding='UTF8') as m:\n",
    "    reader = csv.reader(m, )\n",
    "    abr_list = list(reader)\n",
    "\n",
    "abr_list=abr_list[1:]\n",
    "\n",
    "def Convert(tup, di):\n",
    "    for a, b in tup:\n",
    "        di.setdefault(a, []).append(b)\n",
    "    return di\n",
    "\n",
    "abbr_dic = {}\n",
    "abbr_dic = Convert(abr_list, abbr_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reformat the df removing unnecessary abbreviations and reformat the definitionc in (‖'def.')\n",
    "\n",
    "for word in range(0,len(df)):\n",
    "    for abbr in df['Abbreviation'][word]:\n",
    "        try:\n",
    "            if abbr_dic[abbr]==1:\n",
    "                df['Abbreviation'][word]=df['Abbreviation'][word].remove(abbr)\n",
    "            else:\n",
    "                df['Definition'][word]=df['Definition'][word].replace(abbr,'')\n",
    "        except:\n",
    "            pass\n",
    "    # Remove extra spaces\n",
    "    df['Definition'][word]=' '.join(df['Definition'][word].strip().split())\n",
    "    \n",
    "    # Format the definition inline\n",
    "    df['Definition'][word]=df['Definition'][word].replace(' (‖',',').replace(')',', ')\n",
    "    \n",
    "    # Remove spare punctuation\n",
    "    end=-len(df['Definition'][word])\n",
    "    while df['Definition'][word][-1] in '!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~ ':\n",
    "        df['Definition'][word]= df['Definition'][word][0:-1]\n",
    "            \n",
    "    # Ensure initial upercase and end with '.'\n",
    "    df['Definition'][word]=df['Definition'][word][0].upper() + df['Definition'][word][1:] + '.'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(r'dictionary_RAE_c_df.csv', index = False, encoding='utf-8')\n",
    "df[0:51]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
